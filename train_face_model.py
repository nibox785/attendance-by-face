"""
Script t·ª± ƒë·ªông train face recognition model t·ª´ ·∫£nh sinh vi√™n
S·ª≠ d·ª•ng: python train_face_model.py
"""

import os
import pickle
import cv2
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
from main import facenet
from main.align import detect_face
import warnings

warnings.filterwarnings('ignore')

# Configuration
INPUT_IMAGE_SIZE = 160
FACENET_MODEL_PATH = 'main/Models/20180402-114759.pb'
OUTPUT_CLASSIFIER_PATH = 'main/Models/facemodel.pkl'
FACE_DATA_DIR = 'main/Dataset/FaceData'
MIN_FACE_SIZE = 20
CONFIDENCE_THRESHOLD = 0.95

def load_and_align_data(image_paths, image_size=160, margin=44, gpu_memory_fraction=1.0):
    """
    Load v√† align faces t·ª´ images
    """
    minsize = 20
    threshold = [0.6, 0.7, 0.7]
    factor = 0.709
    
    print('Creating networks and loading parameters')
    with tf.Graph().as_default():
        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)
        sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options, log_device_placement=False))
        with sess.as_default():
            pnet, rnet, onet = detect_face.create_mtcnn(sess, None)
    
    nrof_samples = len(image_paths)
    img_list = []
    
    for i, image_path in enumerate(image_paths):
        img = cv2.imread(image_path)
        if img is None:
            print(f'‚ö†Ô∏è Cannot read: {image_path}')
            continue
            
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # Detect face
        bounding_boxes, _ = detect_face.detect_face(img_rgb, minsize, pnet, rnet, onet, threshold, factor)
        
        if len(bounding_boxes) < 1:
            print(f'‚ö†Ô∏è No face detected: {image_path}')
            continue
            
        det = np.squeeze(bounding_boxes[0, 0:4])
        bb = np.zeros(4, dtype=np.int32)
        bb[0] = np.maximum(det[0] - margin / 2, 0)
        bb[1] = np.maximum(det[1] - margin / 2, 0)
        bb[2] = np.minimum(det[2] + margin / 2, img.shape[1])
        bb[3] = np.minimum(det[3] + margin / 2, img.shape[0])
        
        cropped = img_rgb[bb[1]:bb[3], bb[0]:bb[2], :]
        aligned = cv2.resize(cropped, (image_size, image_size), interpolation=cv2.INTER_CUBIC)
        
        prewhitened = facenet.prewhiten(aligned)
        img_list.append(prewhitened)
        
        if (i + 1) % 10 == 0:
            print(f'Processed {i + 1}/{nrof_samples} images')
    
    return np.stack(img_list) if img_list else np.array([])

def train_classifier(data_dir, model_path, classifier_filename):
    """
    Train SVM classifier t·ª´ face embeddings
    """
    print(f'\nüöÄ B·∫Øt ƒë·∫ßu training face recognition model...')
    print(f'üìÅ Data directory: {data_dir}')
    
    # Load facenet model
    print('\nüì¶ Loading FaceNet model...')
    facenet.load_model(model_path)
    
    # Get image paths v√† labels
    dataset = []
    image_paths = []
    labels = []
    
    if not os.path.exists(data_dir):
        print(f'‚ùå Th∆∞ m·ª•c {data_dir} kh√¥ng t·ªìn t·∫°i!')
        print(f'üí° Vui l√≤ng t·∫°o th∆∞ m·ª•c v√† th√™m ·∫£nh sinh vi√™n theo c·∫•u tr√∫c:')
        print(f'   {data_dir}/MSSV_1/anh1.jpg')
        print(f'   {data_dir}/MSSV_1/anh2.jpg')
        print(f'   {data_dir}/MSSV_2/anh1.jpg')
        return False
    
    class_dirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]
    
    if not class_dirs:
        print(f'‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c n√†o trong {data_dir}!')
        return False
    
    print(f'\nüìä T√¨m th·∫•y {len(class_dirs)} sinh vi√™n:')
    
    for class_name in class_dirs:
        class_dir = os.path.join(data_dir, class_name)
        images = [f for f in os.listdir(class_dir) 
                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        print(f'   - {class_name}: {len(images)} ·∫£nh')
        
        for img in images:
            img_path = os.path.join(class_dir, img)
            image_paths.append(img_path)
            labels.append(class_name)
    
    if not image_paths:
        print('‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o!')
        return False
    
    print(f'\nüñºÔ∏è T·ªïng c·ªông: {len(image_paths)} ·∫£nh')
    
    # Load and align faces
    print('\nüîç Detecting v√† aligning faces...')
    images = load_and_align_data(image_paths, INPUT_IMAGE_SIZE)
    
    if len(images) == 0:
        print('‚ùå Kh√¥ng detect ƒë∆∞·ª£c khu√¥n m·∫∑t n√†o!')
        return False
    
    print(f'‚úÖ Detected {len(images)} faces')
    
    # Get embeddings
    print('\nüß† Extracting face embeddings...')
    graph = tf.compat.v1.get_default_graph()
    images_placeholder = graph.get_tensor_by_name("input:0")
    embeddings_tensor = graph.get_tensor_by_name("embeddings:0")
    phase_train_placeholder = graph.get_tensor_by_name("phase_train:0")
    
    sess = tf.compat.v1.Session(graph=graph)
    
    batch_size = 90
    nrof_images = len(images)
    nrof_batches = int(np.ceil(1.0 * nrof_images / batch_size))
    emb_array = np.zeros((nrof_images, 512))
    
    for i in range(nrof_batches):
        start_index = i * batch_size
        end_index = min((i + 1) * batch_size, nrof_images)
        paths_batch = images[start_index:end_index]
        feed_dict = {images_placeholder: paths_batch, phase_train_placeholder: False}
        emb_array[start_index:end_index, :] = sess.run(embeddings_tensor, feed_dict=feed_dict)
        
        if (i + 1) % 10 == 0:
            print(f'Processed {i + 1}/{nrof_batches} batches')
    
    # Train SVM classifier
    print('\nüéì Training SVM classifier...')
    label_encoder = LabelEncoder()
    labels_encoded = label_encoder.fit_transform(labels[:len(images)])
    
    # Check if only 1 class (1 student)
    unique_classes = len(set(labels_encoded))
    
    if unique_classes == 1:
        print(f'\n‚ö†Ô∏è CH√ö √ù: Ch·ªâ c√≥ 1 sinh vi√™n trong d·ªØ li·ªáu!')
        print(f'   ‚Üí T·∫°o "dummy classifier" cho single-class recognition')
        print(f'   ‚Üí Model s·∫Ω lu√¥n nh·∫≠n di·ªán l√†: {labels[0]}')
        
        # T·∫°o dummy classifier - kh√¥ng train SVM
        model = None  # S·∫Ω x·ª≠ l√Ω ri√™ng trong recognition code
    else:
        # S·ª≠ d·ª•ng probability=True ƒë·ªÉ c√≥ predict_proba
        print(f'   S·ªë l∆∞·ª£ng sinh vi√™n: {unique_classes}')
        model = SVC(kernel='linear', probability=True, C=1.0)
        model.fit(emb_array, labels_encoded)
    
    class_names = label_encoder.classes_
    
    # Save model
    print(f'\nüíæ Saving classifier to {classifier_filename}...')
    with open(classifier_filename, 'wb') as outfile:
        pickle.dump((model, class_names), outfile)
    
    print(f'\n‚úÖ Training ho√†n t·∫•t!')
    print(f'üìä Th·ªëng k√™:')
    print(f'   - S·ªë sinh vi√™n: {len(class_names)}')
    print(f'   - T·ªïng s·ªë ·∫£nh: {len(images)}')
    print(f'   - Trung b√¨nh: {len(images)/len(class_names):.1f} ·∫£nh/sinh vi√™n')
    print(f'\nüë• Danh s√°ch sinh vi√™n ƒë√£ train:')
    for i, name in enumerate(class_names, 1):
        count = labels[:len(images)].count(name)
        print(f'   {i}. {name} ({count} ·∫£nh)')
    
    return True

def create_sample_structure():
    """
    T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c m·∫´u
    """
    print('\nüìÅ T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c m·∫´u...')
    
    sample_students = ['2011003929', '2011010091', '2011010708', '2011020456', '2011030789']
    
    for student in sample_students:
        student_dir = os.path.join(FACE_DATA_DIR, student)
        os.makedirs(student_dir, exist_ok=True)
    
    print(f'‚úÖ ƒê√£ t·∫°o th∆∞ m·ª•c t·∫°i: {FACE_DATA_DIR}')
    print(f'\nüí° H∆∞·ªõng d·∫´n th√™m ·∫£nh:')
    print(f'   1. V√†o th∆∞ m·ª•c {FACE_DATA_DIR}/MSSV')
    print(f'   2. Th√™m 5-10 ·∫£nh khu√¥n m·∫∑t c·ªßa sinh vi√™n')
    print(f'   3. ·∫¢nh n√™n:')
    print(f'      - R√µ n√©t, √°nh s√°ng t·ªët')
    print(f'      - Nh√¨n th·∫≥ng v√†o camera')
    print(f'      - ƒêa d·∫°ng g√≥c ƒë·ªô (tr√°i, ph·∫£i, h∆°i nghi√™ng)')
    print(f'      - K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu 200x200 pixels')
    print(f'   4. Ch·∫°y l·∫°i: python train_face_model.py')

if __name__ == '__main__':
    print('=' * 60)
    print('üéì FACE RECOGNITION MODEL TRAINER')
    print('=' * 60)
    
    # Ki·ªÉm tra facenet model
    if not os.path.exists(FACENET_MODEL_PATH):
        print(f'‚ùå Kh√¥ng t√¨m th·∫•y FaceNet model: {FACENET_MODEL_PATH}')
        print(f'üí° Vui l√≤ng download model t·ª´:')
        print(f'   https://drive.google.com/file/d/1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-/view')
        exit(1)
    
    # Ki·ªÉm tra face data directory
    if not os.path.exists(FACE_DATA_DIR):
        print(f'‚ö†Ô∏è Th∆∞ m·ª•c {FACE_DATA_DIR} ch∆∞a t·ªìn t·∫°i!')
        choice = input('B·∫°n c√≥ mu·ªën t·∫°o c·∫•u tr√∫c th∆∞ m·ª•c m·∫´u? (y/n): ')
        if choice.lower() == 'y':
            create_sample_structure()
        exit(0)
    
    # Train classifier
    success = train_classifier(FACE_DATA_DIR, FACENET_MODEL_PATH, OUTPUT_CLASSIFIER_PATH)
    
    if success:
        print('\nüéâ SUCCESS! Model ƒë√£ s·∫µn s√†ng s·ª≠ d·ª•ng!')
        print(f'üìç File model: {OUTPUT_CLASSIFIER_PATH}')
        print(f'\nüöÄ B∆∞·ªõc ti·∫øp theo:')
        print(f'   1. Kh·ªüi ƒë·ªông server: python manage.py runserver')
        print(f'   2. V√†o trang ƒëi·ªÉm danh b·∫±ng khu√¥n m·∫∑t')
        print(f'   3. Test nh·∫≠n di·ªán v·ªõi sinh vi√™n ƒë√£ train')
    else:
        print('\n‚ùå Training th·∫•t b·∫°i! Vui l√≤ng ki·ªÉm tra l·∫°i.')
        print(f'\nüí° G·ª£i √Ω:')
        print(f'   - Ki·ªÉm tra ·∫£nh c√≥ r√µ n√©t kh√¥ng')
        print(f'   - M·ªói sinh vi√™n c·∫ßn √≠t nh·∫•t 3-5 ·∫£nh')
        print(f'   - ·∫¢nh ph·∫£i c√≥ khu√¥n m·∫∑t r√µ r√†ng')
