import pickle
from datetime import datetime
import os
import cv2
import imutils
import numpy as np
import tensorflow as tf
from imutils.video import VideoStream
from main.src.anti_spoof_predict import AntiSpoofPredict
from main.src.generate_patches import CropImage
from main.src.utility import parse_model_name
from main import facenet
from main.align import detect_face
from main.models import Classroom, Attendance, StudentInfo, StudentClassDetails, ClassSession
import warnings
import re
from difflib import SequenceMatcher

# ...

# Tr∆∞·ªõc khi g·ªçi h√†m c√≥ c·∫£nh b√°o
with warnings.catch_warnings():
    warnings.simplefilter("ignore")

model_test = AntiSpoofPredict(0)
image_cropper = CropImage()
model_dir = "main/resources/anti_spoof_models"


def normalize_student_id(student_id):
    """
    Chu·∫©n h√≥a m√£ sinh vi√™n: lo·∫°i b·ªè kho·∫£ng tr·∫Øng, k√Ω t·ª± ƒë·∫∑c bi·ªát
    """
    if not student_id:
        return ""
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng, lowercase, ch·ªâ gi·ªØ l·∫°i ch·ªØ s·ªë
    return re.sub(r'[^a-zA-Z0-9]', '', str(student_id)).strip().upper()


def fuzzy_match_student(recognized_name, threshold=0.85):
    """
    T√¨m sinh vi√™n kh·ªõp v·ªõi t√™n ƒë∆∞·ª£c nh·∫≠n di·ªán (fuzzy matching)
    
    Args:
        recognized_name: T√™n t·ª´ model (c√≥ th·ªÉ l√† MSSV ho·∫∑c t√™n)
        threshold: Ng∆∞·ª°ng ƒë·ªô t∆∞∆°ng ƒë·ªìng (0-1)
    
    Returns:
        StudentInfo object ho·∫∑c None
    """
    normalized_input = normalize_student_id(recognized_name)
    
    # Th·ª≠ t√¨m ch√≠nh x√°c tr∆∞·ªõc
    try:
        return StudentInfo.objects.get(id_student=normalized_input)
    except StudentInfo.DoesNotExist:
        pass
    
    # Fuzzy matching v·ªõi t·∫•t c·∫£ sinh vi√™n
    all_students = StudentInfo.objects.all()
    best_match = None
    best_score = 0
    
    for student in all_students:
        # So s√°nh v·ªõi MSSV
        score_id = SequenceMatcher(None, normalized_input, 
                                   normalize_student_id(student.id_student)).ratio()
        
        # So s√°nh v·ªõi t√™n (chu·∫©n h√≥a)
        normalized_name = normalize_student_id(student.student_name)
        score_name = SequenceMatcher(None, normalized_input, normalized_name).ratio()
        
        # L·∫•y score cao h∆°n
        score = max(score_id, score_name)
        
        if score > best_score and score >= threshold:
            best_score = score
            best_match = student
    
    if best_match:
        print(f"‚ö†Ô∏è Fuzzy match: '{recognized_name}' ‚Üí {best_match.id_student} ({best_match.student_name}) - Score: {best_score:.2f}")
    
    return best_match


def enhance_image(image):
    """
    C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ·∫£nh ƒë·ªÉ nh·∫≠n di·ªán t·ªët h∆°n
    - TƒÉng ƒë·ªô s√°ng n·∫øu qu√° t·ªëi
    - TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n
    - Gi·∫£m noise
    """
    # Chuy·ªÉn sang LAB color space
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    
    # √Åp d·ª•ng CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    
    # Merge l·∫°i v√† chuy·ªÉn v·ªÅ BGR
    enhanced = cv2.merge([l, a, b])
    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
    
    # Gi·∫£m noise
    enhanced = cv2.fastNlMeansDenoisingColored(enhanced, None, 10, 10, 7, 21)
    
    return enhanced


# Function to draw a progress bar


def insert_attendance(session_id, student_id):
    """
    C·∫≠p nh·∫≠t ƒëi·ªÉm danh khi nh·∫≠n di·ªán khu√¥n m·∫∑t th√†nh c√¥ng
    LOGIC M·ªöI: Kh√¥ng t·∫°o b·∫£n ghi cho t·∫•t c·∫£ SV, ch·ªâ c·∫≠p nh·∫≠t ng∆∞·ªùi ƒë∆∞·ª£c nh·∫≠n di·ªán
    
    Args:
        session_id: ID c·ªßa bu·ªïi h·ªçc (ClassSession)
        student_id: M√£ sinh vi√™n ƒë∆∞·ª£c nh·∫≠n di·ªán (t·ª´ model)
    
    Returns:
        str: Th√¥ng b√°o k·∫øt qu·∫£
    """
    print(f"\n‚û°Ô∏è insert_attendance called: session_id={session_id}, student_id='{student_id}'")
    
    try:
        session = ClassSession.objects.get(pk=session_id)
    except ClassSession.DoesNotExist:
        return f"ERROR: Kh√¥ng t√¨m th·∫•y bu·ªïi h·ªçc v·ªõi ID {session_id}"
    
    # Ki·ªÉm tra bu·ªïi h·ªçc c√≥ ƒëang m·ªü kh√¥ng
    if session.status != 'OPEN':
        return f"ERROR: Bu·ªïi h·ªçc ƒë√£ ƒë√≥ng ho·∫∑c ch∆∞a m·ªü. Kh√¥ng th·ªÉ ƒëi·ªÉm danh!"
    
    classroom = session.id_classroom
    current_time = datetime.now()
    begin_time = classroom.begin_time
    
    # T√≠nh to√°n tr·∫°ng th√°i (Mu·ªôn n·∫øu check-in > 15 ph√∫t sau gi·ªù b·∫Øt ƒë·∫ßu)
    time_difference = (datetime.combine(datetime.now(), current_time.time())
                       - datetime.combine(datetime.now(), begin_time))
    
    if time_difference.total_seconds() > 900:  # 15 ph√∫t = 900 gi√¢y
        attendance_status = 3  # Mu·ªôn
        status_text = "Mu·ªôn"
    else:
        attendance_status = 2  # C√≥ m·∫∑t ƒë√∫ng gi·ªù
        status_text = "C√≥ m·∫∑t"
    
    # ‚úÖ C·∫¢I TI·ªÜN: Chu·∫©n h√≥a v√† fuzzy match student ID
    normalized_id = normalize_student_id(student_id)
    print(f"üîç Normalized: '{student_id}' ‚Üí '{normalized_id}'")
    
    # Th·ª≠ t√¨m ch√≠nh x√°c tr∆∞·ªõc
    student_info = None
    try:
        student_info = StudentInfo.objects.get(id_student=normalized_id)
        print(f"‚úÖ Exact match: {student_info.id_student} - {student_info.student_name}")
    except StudentInfo.DoesNotExist:
        print(f"‚ö†Ô∏è Exact match failed, trying fuzzy match...")
        # Th·ª≠ fuzzy matching
        student_info = fuzzy_match_student(student_id, threshold=0.80)
        
        if not student_info:
            # Li·ªát k√™ t·∫•t c·∫£ sinh vi√™n ƒë·ªÉ debug
            all_students = StudentInfo.objects.all()[:10]
            student_list = ", ".join([f"{s.id_student}" for s in all_students])
            return f"ERROR: Kh√¥ng t√¨m th·∫•y sinh vi√™n '{student_id}' (normalized: '{normalized_id}').\nC√≥ trong DB: {student_list}..."
    
    # Ki·ªÉm tra sinh vi√™n c√≥ ƒëƒÉng k√Ω l·ªõp n√†y kh√¥ng
    if not StudentClassDetails.objects.filter(
        id_classroom=classroom,
        id_student=student_info
    ).exists():
        return f"ERROR: Sinh vi√™n {student_info.student_name} ({student_info.id_student}) kh√¥ng c√≥ trong l·ªõp {classroom.name}"
    
    # C·∫≠p nh·∫≠t ho·∫∑c t·∫°o b·∫£n ghi ƒëi·ªÉm danh
    try:
        attendance = Attendance.objects.get(
            id_session=session,
            id_student=student_info
        )
        
        # Ki·ªÉm tra ƒë√£ ƒëi·ªÉm danh ch∆∞a (status != 1 V·∫Øng)
        if attendance.attendance_status != 1:
            return f"INFO: {student_info.student_name} ({student_info.id_student}) ƒë√£ ƒëi·ªÉm danh l√∫c {attendance.check_in_time.strftime('%H:%M:%S')}"
        
        # C·∫≠p nh·∫≠t t·ª´ V·∫Øng ‚Üí C√≥ m·∫∑t/Mu·ªôn
        attendance.attendance_status = attendance_status
        attendance.check_in_time = current_time
        attendance.check_in_method = 'FACE'
        attendance.save()
        
        print(f"‚úì ƒêi·ªÉm danh th√†nh c√¥ng: {student_info.student_name} ({student_info.id_student}) - {status_text}")
        return f"SUCCESS: {student_info.student_name} ({student_info.id_student}) - {status_text}"
        
    except Attendance.DoesNotExist:
        # Tr∆∞·ªùng h·ª£p bu·ªïi h·ªçc ch∆∞a kh·ªüi t·∫°o b·∫£n ghi V·∫Øng
        # T·∫°o m·ªõi b·∫£n ghi ƒëi·ªÉm danh
        attendance = Attendance.objects.create(
            id_session=session,
            id_classroom=classroom,
            id_student=student_info,
            check_in_time=current_time,
            attendance_status=attendance_status,
            check_in_method='FACE'
        )
        print(f"‚úì ƒêi·ªÉm danh th√†nh c√¥ng (t·∫°o m·ªõi): {student_info.student_name} ({student_info.id_student}) - {status_text}")
        return f"SUCCESS: {student_info.student_name} ({student_info.id_student}) - {status_text}"
        
    except Exception as e:
        print(f"‚úó L·ªói khi ƒëi·ªÉm danh: {e}")
        return f"ERROR: {str(e)}"


def draw_progress_bar(frame, progress, x, y, w, h, confidence=0):
    """V·∫Ω thanh ti·∫øn tr√¨nh v√† hi·ªÉn th·ªã th√¥ng tin debug"""
    bar_width = 200
    bar_height = 25
    bar_x = x
    bar_y = y - 35
    
    # V·∫Ω n·ªÅn thanh
    cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (50, 50, 50), -1)
    
    # V·∫Ω ti·∫øn ƒë·ªô
    filled_width = int(bar_width * min(progress, 1.0))
    color = (0, 255, 0) if progress < 1.0 else (0, 255, 255)  # Xanh l√° -> V√†ng khi ƒë·ªß
    cv2.rectangle(frame, (bar_x, bar_y), (bar_x + filled_width, bar_y + bar_height), color, -1)
    
    # Hi·ªÉn th·ªã %
    percent_text = f"{int(progress * 100)}%"
    cv2.putText(frame, percent_text, (bar_x + bar_width + 10, bar_y + 18), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    # Hi·ªÉn th·ªã confidence n·∫øu c√≥
    if confidence > 0:
        conf_text = f"Conf: {confidence:.2f}"
        cv2.putText(frame, conf_text, (bar_x, bar_y - 5), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)


def main(session_id):
    """
    H√†m ch√≠nh x·ª≠ l√Ω nh·∫≠n di·ªán khu√¥n m·∫∑t v√† ƒëi·ªÉm danh (Optimized Version)
    
    Args:
        session_id: ID c·ªßa bu·ªïi h·ªçc (ClassSession) thay v√¨ id_classroom
    """

    INPUT_IMAGE_SIZE = 160
    CLASSIFIER_PATH = 'main/Models/facemodel.pkl'
    FACENET_MODEL_PATH = 'main/Models/20180402-114759.pb'

    # Ki·ªÉm tra model t·ªìn t·∫°i
    if not os.path.exists(CLASSIFIER_PATH):
        print("=" * 70)
        print("‚ùå L·ªñI: Model ch∆∞a ƒë∆∞·ª£c train!")
        print("=" * 70)
        print("File kh√¥ng t·ªìn t·∫°i:", CLASSIFIER_PATH)
        print("\nüìã H∆Ø·ªöNG D·∫™N KH·∫ÆC PH·ª§C:")
        print("1. Th√™m ·∫£nh sinh vi√™n v√†o: main/Dataset/FaceData/MSSV/")
        print("   - M·ªói sinh vi√™n c·∫ßn 20-30 ·∫£nh")
        print("2. Ch·∫°y l·ªánh: python train_face_model.py")
        print("3. Sau khi train xong, quay l·∫°i ƒëi·ªÉm danh")
        print("\nüìñ Chi ti·∫øt: ƒê·ªçc file SETUP_FACE_RECOGNITION.md")
        print("=" * 70)
        
        # T·∫°o frame th√¥ng b√°o l·ªói
        while True:
            frame = np.zeros((480, 640, 3), dtype=np.uint8)
            cv2.putText(frame, "MODEL CHUA DUOC TRAIN!", (50, 200), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            cv2.putText(frame, "Vui long chay: python train_face_model.py", (20, 250), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)
            cv2.putText(frame, "Chi tiet: SETUP_FACE_RECOGNITION.md", (50, 300), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)
            
            ret, jpeg = cv2.imencode('.jpg', frame)
            frame_bytes = jpeg.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n\r\n')

    with open(CLASSIFIER_PATH, 'rb') as file:
        model, class_names = pickle.load(file)
    print("Custom Classifier, Successfully loaded")

    # Load feature extraction model outside the session
    facenet.load_model(FACENET_MODEL_PATH)
    graph = tf.compat.v1.get_default_graph()
    images_placeholder = graph.get_tensor_by_name("input:0")
    embeddings = graph.get_tensor_by_name("embeddings:0")
    phase_train_placeholder = graph.get_tensor_by_name("phase_train:0")

    # ‚úÖ OPTIMIZATION: TƒÉng FPS v√† gi·∫£m buffer delay
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FPS, 30)  # TƒÉng FPS
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Gi·∫£m buffer lag

    global justscanned
    global pause_cnt
    justscanned = False
    pause_cnt = 0
    current_face_name = ""
    current_face_progress = 0

    # Initialize an empty list to store recognized names
    recognized_names = []
    sess = tf.compat.v1.Session(graph=graph)
    
    # ‚úÖ OPTIMIZATION: Frame skipping counter
    frame_count = 0
    skip_frames = 2  # Ch·ªâ x·ª≠ l√Ω m·ªói frame th·ª© 2 (tƒÉng 50% t·ªëc ƒë·ªô)

    while cap.isOpened():
        isSuccess, frame = cap.read()
        if isSuccess:
            frame_count += 1
            
            # ‚úÖ OPTIMIZATION: Skip frames ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω
            # Ch·ªâ x·ª≠ l√Ω face detection m·ªói 2 frames
            if frame_count % skip_frames != 0:
                ret, buffer = cv2.imencode('.jpg', frame)
                frame_bytes = buffer.tobytes()
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
                continue
            
            image_bbox = model_test.get_bbox(frame)
            if image_bbox is not None:
                x, y, w, h = (image_bbox[0]), (image_bbox[1] - 50), (image_bbox[0] + image_bbox[2]), (
                        image_bbox[1] + image_bbox[3])
                height, width, _ = frame.shape

                # ‚úÖ OPTIMIZATION: Ch·ªâ d√πng 1 anti-spoof model thay v√¨ loop qua 3 models
                # TƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω g·∫•p 3 l·∫ßn ph·∫ßn anti-spoof
                prediction = np.zeros((1, 3))
                
                # Ch·ªâ s·ª≠ d·ª•ng model 2.7_80x80_MiniFASNetV2.pth (model t·ªët nh·∫•t)
                best_model = "2.7_80x80_MiniFASNetV2.pth"
                if os.path.exists(os.path.join(model_dir, best_model)):
                    h_input, w_input, model_type, scale = parse_model_name(best_model)
                    param = {
                        "org_img": frame,
                        "bbox": image_bbox,
                        "scale": scale,
                        "out_w": w_input,
                        "out_h": h_input,
                        "crop": True,
                    }
                    if scale is None:
                        param["crop"] = False
                    img = image_cropper.crop(**param)
                    prediction = model_test.predict(img, os.path.join(model_dir, best_model)) * 3  # Nh√¢n 3 ƒë·ªÉ b√π tr·ª´ vi·ªác ch·ªâ d√πng 1 model
                else:
                    # Fallback: n·∫øu kh√¥ng t√¨m th·∫•y model t·ªët nh·∫•t, d√πng model ƒë·∫ßu ti√™n
                    model_name = os.listdir(model_dir)[0]
                    h_input, w_input, model_type, scale = parse_model_name(model_name)
                    param = {
                        "org_img": frame,
                        "bbox": image_bbox,
                        "scale": scale,
                        "out_w": w_input,
                        "out_h": h_input,
                        "crop": True,
                    }
                    if scale is None:
                        param["crop"] = False
                    img = image_cropper.crop(**param)
                    prediction = model_test.predict(img, os.path.join(model_dir, model_name)) * 3

                label = np.argmax(prediction)
                value = prediction[0][label] / 2
                if label == 1:
                    cropped = frame[y:h, x:w, :]
                    # Check if the cropped image is not empty
                    if cropped is not None and cropped.size > 0:
                        # ‚úÖ C·∫¢I TI·ªÜN: TƒÉng ch·∫•t l∆∞·ª£ng ·∫£nh tr∆∞·ªõc khi nh·∫≠n di·ªán
                        enhanced_crop = enhance_image(cropped)
                        
                        scaled = cv2.resize(enhanced_crop, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),
                                            interpolation=cv2.INTER_CUBIC)
                        scaled = facenet.prewhiten(scaled)
                        scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)
                        feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}
                        emb_array = sess.run(embeddings, feed_dict=feed_dict)
                        
                        # ‚úÖ X·ª¨ L√ù TR∆Ø·ªúNG H·ª¢P CH·ªà C√ì 1 SINH VI√äN
                        if model is None:
                            # Single-class mode: lu√¥n tr·∫£ v·ªÅ sinh vi√™n duy nh·∫•t v·ªõi confidence cao
                            best_name = class_names[0]
                            best_class_probabilities = np.array([0.95])  # High confidence
                            predictions = np.array([[0.95]])
                            top_3_names = [best_name]
                            top_3_probs = [0.95]
                        else:
                            # Multi-class mode: d√πng SVM classifier
                            predictions = model.predict_proba(emb_array)
                            best_class_indices = np.argmax(predictions, axis=1)
                            best_class_probabilities = predictions[
                                np.arange(len(best_class_indices)), best_class_indices]
                            best_name = class_names[best_class_indices[0]]
                            
                            # L·∫•y top 3 predictions ƒë·ªÉ hi·ªÉn th·ªã
                            top_3_idx = np.argsort(predictions[0])[-3:][::-1]
                            top_3_names = [class_names[i] for i in top_3_idx]
                            top_3_probs = [predictions[0][i] for i in top_3_idx]

                        # ‚úÖ C·∫¢I TI·ªÜN: Gi·∫£m threshold t·ª´ 0.85 ‚Üí 0.50 ƒë·ªÉ d·ªÖ nh·∫≠n di·ªán h∆°n
                        # V√† ki·ªÉm tra kho·∫£ng c√°ch gi·ªØa top 1 v√† top 2 (margin)
                        confidence_threshold = 0.50
                        margin_threshold = 0.15  # Top 1 ph·∫£i h∆°n top 2 √≠t nh·∫•t 15%
                        
                        is_confident = (best_class_probabilities[0] > confidence_threshold and 
                                      (len(top_3_probs) < 2 or (top_3_probs[0] - top_3_probs[1]) > margin_threshold))
                        
                        if is_confident:
                            if best_name not in recognized_names:
                                if current_face_name != best_name:
                                    current_face_name = best_name
                                    current_face_progress = 0
                                    justscanned = False
                                elif not justscanned:
                                    current_face_progress += skip_frames
                                    # ‚úÖ GI·∫¢M xu·ªëng 10 frames (nhanh h∆°n n·ªØa)
                                    progress = current_face_progress / 10
                                    draw_progress_bar(frame, progress, x, y, w, h, best_class_probabilities[0])

                                # V·∫Ω khung xanh l√°
                                cv2.rectangle(frame, (x, y), (w, h), (0, 255, 0), 3)
                                
                                # Hi·ªÉn th·ªã t√™n v√† confidence
                                text_x = x
                                text_y = h + 25
                                
                                # T√™n sinh vi√™n v√† MSSV (ch·ªØ l·ªõn, m√†u v√†ng)
                                display_text = f"{best_name}"
                                # Th·ª≠ l·∫•y th√¥ng tin ƒë·∫ßy ƒë·ªß t·ª´ DB
                                try:
                                    student_info = fuzzy_match_student(best_name, threshold=0.70)
                                    if student_info:
                                        display_text = f"{student_info.id_student} - {student_info.student_name}"
                                except:
                                    pass
                                
                                cv2.putText(frame, display_text, (text_x, text_y), 
                                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                                
                                # Confidence score
                                conf_text = f"{best_class_probabilities[0]:.1%}"
                                cv2.putText(frame, conf_text, (text_x, text_y + 25), 
                                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                                
                                # Hi·ªÉn th·ªã top 3 predictions (debug info)
                                debug_y = text_y + 50
                                for i, (name, prob) in enumerate(zip(top_3_names[:3], top_3_probs[:3])):
                                    debug_text = f"{i+1}. {name}: {prob:.1%}"
                                    color = (0, 255, 255) if i == 0 else (200, 200, 200)
                                    cv2.putText(frame, debug_text, (text_x, debug_y + i*20), 
                                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

                                # ‚úÖ Gi·∫£m xu·ªëng 10 frames
                                if current_face_progress >= 10:
                                    justscanned = True
                                    recognized_names.append(best_name)
                                    insert = insert_attendance(session_id, best_name)
                                    print(insert)
                                    if current_face_name != "SUCCESS":
                                        print("Success: Face Recognized as", insert)
                            else:
                                # ƒê√£ ƒëi·ªÉm danh r·ªìi
                                message = f"{best_name} - DA DIEM DANH"
                                cv2.rectangle(frame, (x, y), (w, h), (0, 0, 255), 3)
                                cv2.putText(frame, message, (x, y - 10), 
                                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                        else:
                            # Kh√¥ng ƒë·ªß confidence - hi·ªÉn th·ªã th√¥ng tin debug
                            current_face_name = "LOW_CONFIDENCE"
                            current_face_progress = 0
                            justscanned = False
                            
                            # V·∫Ω khung v√†ng (c·∫£nh b√°o)
                            cv2.rectangle(frame, (x, y), (w, h), (0, 165, 255), 3)
                            
                            # Hi·ªÉn th·ªã top prediction v√† confidence
                            text_x = x
                            text_y = h + 25
                            
                            warning_text = "KHONG CHAC CHAN"
                            cv2.putText(frame, warning_text, (text_x, text_y), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)
                            
                            # Hi·ªÉn th·ªã top 3 ƒë·ªÉ debug
                            debug_y = text_y + 25
                            for i, (name, prob) in enumerate(zip(top_3_names[:3], top_3_probs[:3])):
                                debug_text = f"{i+1}. {name}: {prob:.1%}"
                                cv2.putText(frame, debug_text, (text_x, debug_y + i*20), 
                                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 165, 255), 1)
                            
                            # H∆∞·ªõng d·∫´n
                            guide_text = "Dung gan camera, nhin thang"
                            cv2.putText(frame, guide_text, (text_x, debug_y + 70), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
                else:
                    result_text = "Gia mao !!!".format(value)
                    color = (0, 255, 255)
                    cv2.rectangle(
                        frame,
                        (image_bbox[0], image_bbox[1] - 50),
                        (image_bbox[0] + image_bbox[2], image_bbox[1] + image_bbox[3]),
                        # Increase the height by 20 pixels
                        color, 2)

                    cv2.putText(
                        frame,
                        result_text,
                        (image_bbox[0], image_bbox[1]),
                        cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, color, thickness=1,
                        lineType=2)

        ret, buffer = cv2.imencode('.jpg', frame)
        frame = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

    sess.close()
    cap.release()
    cv2.destroyAllWindows()
